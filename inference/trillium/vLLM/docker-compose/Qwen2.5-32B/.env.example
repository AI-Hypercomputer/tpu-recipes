# This file provides the default configuration for running the Qwen2.5-32B model.
# Copy this file to .env and edit it with your specific values.

# Your username, used by the Makefile for container operations.
# This will be set automatically by 'make setup'
USER=your-username

# Docker image to use
DOCKER_URI=vllm/vllm-tpu:nightly

# Your Hugging Face token for downloading models
HF_TOKEN=<your-hugging-face-token-here>

# --- Server Configuration ---
SEED=42
GPU_MEMORY_UTILIZATION=0.98
DISABLE_LOG_REQUESTS=--disable-log-requests
# This model requires the V1 API flag
VLLM_USE_V1=1

# --- Qwen2.5-32B Configuration ---
# Note: The original recipe specified 10gb, but 100gb is a more realistic value for a 32B model.
SHM_SIZE=100gb
MODEL_NAME=Qwen/Qwen2.5-32B
MAX_MODEL_LEN=4096
TP=4
MAX_NUM_BATCHED_TOKENS=2048
MAX_NUM_SEQS=128
